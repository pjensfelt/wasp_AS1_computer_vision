{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Feature extraction\nThis notebook will show you how to extract features from an image\n\nFrom http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_table_of_contents_feature2d/py_table_of_contents_feature2d.html"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport cv2 as cv"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Load the image\nWhen you have run through the notebook once, go back here and try with different images Take a look at these images for example\n\n* fruits_320_213.jpg\n* mosaic_320_262.jpg\n* image1.jpg"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Feature extraction\nThe code below extracts a variety of features from the input image\n\nSome examples to test on\n* fruits_320_213.jpg\n* mosaic_320_262.jpg\n* image1.jpg\n* noisy_image_example.png\n\n**NOTE** Press ENTER to close the window"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "imagefile = \"test_images/fruits_320_213.jpg\";\n\nimage = cv.imread(imagefile)\nprint(\"The dimension of the image is \" + repr(image.shape))\n\n# Show the input image\ncv.imshow('Input image',image)\n\n\n#####################################################################\n# Extract the Harris corners\n# http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html\n\nimage = cv.imread(imagefile)\ngray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n# Turn the image into a numpy array\ngraynp = np.float32(gray)\n\nharris = cv.cornerHarris(graynp,2,3,0.04)\n\n# Dilate the harris points to make them easier to see\nharris = cv.dilate(harris,None)\n\n# Display only the strongest corneres\noverlayharris = image\noverlayharris[harris>0.01*harris.max()]=[255,0,0]\n\n#####################################################################\n# Shi-Tomasi corners\n\nimage = cv.imread(imagefile)\ngray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n\nst_n_pts = 50\nst_qual = 0.01\nst_dist = 10\nstpts = cv.goodFeaturesToTrack(gray,st_n_pts, st_qual, st_dist)\nstpts = np.int0(stpts)\n\noverlayst = image\n\nfor i in stpts:\n    x,y = i.ravel()\n    cv.circle(overlayst,(x,y),3,[0,255,0],-1)\n\n#####################################################################\n# Extract ORB features\n\nimage = cv.imread(imagefile)\n\n# Create the ORB creator\norb = cv.ORB_create()\n\n# find the keypoints with ORB\norbpts = orb.detect(gray,None)\n\n# compute the descriptors with ORB\norbpts, prbdescr = orb.compute(gray, orbpts)\n\n# Draw only keypoints location,not size and orientation\noverlayorb = cv.drawKeypoints(image, orbpts, None, color=(0,0,255), flags=0)\n\ncv.imshow('Image overlayed with strongest Harris corners', overlayharris)\ncv.imshow('Image overlayed with strongest Shi-Tomasi corners', overlayst)\ncv.imshow('Image overlayed with ORB features', overlayorb)\ncv.waitKey(0)\ncv.destroyAllWindows()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "cv.destroyAllWindows()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
