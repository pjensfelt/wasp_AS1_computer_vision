{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Matching features with both descriptor and geometry\nThis notebook shows how we can match features between frames. This is a core component for many systems. \nFor example when you want to reconstruct a model of the environment, or caluclate how the camera is moving or both at the same time, i.e., simultaneously build a model of the environment and estimating how the camera is moving.. \n\nA feature typically consists of a keypoints (location, i.e., where in the image) and a descriptor (what that part of the image looks like). When performing matching one often uses the descriptor first. In ideal cases the descriptor is so good that it can directly generate only correct matches. In most pratcical cases this is not true and we need to look for the correct matches. \n\nIn the code below we will make use of the ORB feature. ORB is a combination of the FAST detector and the BRIEF descriptor. One of the benefits of ORB is that it is fast to compute and match.\nhttps://www.researchgate.net/publication/221111151_ORB_an_efficient_alternative_to_SIFT_or_SURF\n\nThe first thing we do in the code below is that we make use of David Lowe's ratio test which he defined when he introduced the SIFT feature in https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf. The idea is that we want to only use matches where two points A and B in two images are much better matches than A and the second best match in the second image. \n\nNow we will use the position of the features. We will do this together with the RANSAC algorithm. RANSAC iterates over\n* Draw a minimum set of point matches to calculate the homograhy\n* Calculate the homograhy\n* Check which of the other point matches supports this homography\nWe pick the homography that has the biggest support and use this to define which matches are inliers."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The dimension of img1 is (720, 1280)\nThe dimension of img2 is (720, 1280)\n"
    }
   ],
   "source": "import numpy as np\nimport cv2 as cv\n\n# Load the image as gray scale images\nimg1 = cv.imread('test_images/patrics_foot_1.jpg',0)\nimg2 = cv.imread('test_images/patrics_foot_2.jpg',0)\n#img1 = cv.imread('test_images/pattern_ca_40cm.jpg',0)\n#img2 = cv.imread('test_images/pattern_view2.jpg',0)\nprint(\"The dimension of img1 is \" + repr(img1.shape))\nprint(\"The dimension of img2 is \" + repr(img2.shape))\n\n# Initiate a feature detector\ndetector = cv.ORB_create()\n\n# Find the keypoints and descriptors\nkp1, des1 = detector.detectAndCompute(img1,None)\nkp2, des2 = detector.detectAndCompute(img2,None)\n\n# We use a brute force matcher with default params\nbf = cv.BFMatcher()\nmatches = bf.knnMatch(des1,des2, k=2)\n\n# Apply David Lowe's ratio test to remove bad matches\n# https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf\ngood = []\nfor m,n in matches:\n    if m.distance < 0.75 * n.distance:\n        # I had to change from [m] to m to make the code inside the MIN_MATCH_COUNT section below\n        good.append(m)\n\n# Draw the matches, both all of them and the good ones\nimage_matches_all = cv.drawMatchesKnn(img1,kp1,img2,kp2,matches,None)\n# I had to modify this code to give it the data in the format it wanted\n# Probably some easier way to do this if you actually know Python...\ngood_list_of_lists = []\nfor i in good:\n    good_list_of_lists.append([i])\nimage_matches_good = cv.drawMatchesKnn(img1,kp1,img2,kp2,good_list_of_lists,None)\n\n        \n# Now make use of the geometry to look for matches\n# We calculate the homography between the images and use that to see how \n# many points that support a certain homography. This allows us to \nMIN_MATCH_COUNT = 10\nif len(good)>MIN_MATCH_COUNT:\n    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n\n    M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)\n    matchesMask = mask.ravel().tolist()\n\n    h,w = img1.shape\n    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n    dst = cv.perspectiveTransform(pts,M)\n\n    image_ransac = cv.polylines(img2,[np.int32(dst)],True,255,3, cv.LINE_AA)\n\nelse:\n    print \"Not enough matches are found - %d/%d\" % (len(good),MIN_MATCH_COUNT)\n    matchesMask = None\n\n# Draw the matches\ndraw_params = dict(matchColor = (0,255,0), # draw matches in green color\n                   singlePointColor = None,\n                   matchesMask = matchesMask, # draw only inliers\n                   flags = 2)\nimage_ransac = cv.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n    \n    \ncv.namedWindow(\"All matches between images\", cv.WINDOW_NORMAL)\ncv.resizeWindow(\"All matches between images\", (1000, 300))\ncv.namedWindow(\"Good descriptor matches between images\", cv.WINDOW_NORMAL)\ncv.resizeWindow(\"Good descriptor matches between images\", (1000,380))\ncv.namedWindow(\"RANSAC cleaned matches\", cv.WINDOW_NORMAL)\ncv.resizeWindow(\"RANSAC cleaned matches\", (1000,380))\n\ncv.imshow(\"All matches between images\", image_matches_all)\ncv.imshow(\"Good descriptor matches between images\", image_matches_good)\ncv.imshow(\"RANSAC cleaned matches\", image_ransac)\n\n\n\ncv.waitKey(0)\ncv.destroyAllWindows()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "cv.waitKey(0)\ncv.destroyAllWindows()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
